"""
State Management Performance Optimizer for Adapter Framework

This module implements advanced state management optimizations including:
- Immutable state containers with copy-on-write
- Lightweight state transition management
- Memory-efficient state storage and retrieval
- Smart state sharing and deduplication
- Lazy state evaluation and computation
- Performance monitoring and optimization hints

Key Features:
- Zero-copy state sharing where possible
- Efficient state diff and patch operations
- Memory pool for state objects
- Weak reference management for garbage collection
- Async state operations for non-blocking updates
- State compression for large datasets
"""

import sys
import time
import threading
import weakref
import pickle
import copy
import gc
import hashlib
import json
from typing import Dict, List, Any, Optional, Callable, Tuple, Union, Set, Type, TypeVar, Generic
from dataclasses import dataclass, field, asdict, replace
from collections import defaultdict, deque, OrderedDict
from datetime import datetime, timedelta
from pathlib import Path
from enum import Enum, auto
from functools import wraps, lru_cache
from concurrent.futures import ThreadPoolExecutor
import asyncio
import logging

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

try:
    from ui.adapters.interfaces import AdapterState
    ADAPTER_INTERFACES_AVAILABLE = True
except ImportError as e:
    print(f"Warning: Adapter interfaces not available: {e}")
    ADAPTER_INTERFACES_AVAILABLE = False


T = TypeVar('T')


class StateOperationType(Enum):
    """Types of state operations"""
    READ = auto()
    WRITE = auto()
    UPDATE = auto()
    DELETE = auto()
    BATCH = auto()
    TRANSACTION = auto()


class StateOptimizationStrategy(Enum):
    """State optimization strategies"""
    COPY_ON_WRITE = auto()
    IMMUTABLE = auto()
    SHARED_REFERENCE = auto()
    MEMORY_POOL = auto()
    COMPRESSED = auto()
    LAZY_EVALUATION = auto()


@dataclass
class StateMetrics:
    """Performance metrics for state operations"""
    
    # Operation metrics
    reads_performed: int = 0
    writes_performed: int = 0
    updates_performed: int = 0
    deletes_performed: int = 0
    
    # Performance metrics
    avg_read_time: float = 0.0
    avg_write_time: float = 0.0
    avg_update_time: float = 0.0
    peak_operation_time: float = 0.0
    
    # Memory metrics
    total_memory_bytes: int = 0
    active_states: int = 0
    shared_states: int = 0
    memory_saved_bytes: int = 0
    
    # Optimization metrics
    copy_on_write_saves: int = 0
    lazy_evaluations: int = 0
    state_deduplications: int = 0
    garbage_collections: int = 0
    
    # Error metrics
    operation_errors: int = 0
    memory_errors: int = 0
    serialization_errors: int = 0


@dataclass(frozen=True)
class ImmutableState:
    """
    Immutable state container with efficient copy-on-write semantics
    
    Uses structural sharing to minimize memory usage when creating
    modified versions of the state.
    """
    
    _data: Dict[str, Any] = field(default_factory=dict)
    _version: int = 0
    _created_at: float = field(default_factory=time.time)
    _parent_hash: Optional[str] = None
    
    def __post_init__(self):
        # Freeze the data dictionary to ensure immutability
        if isinstance(self._data, dict):
            object.__setattr__(self, '_data', tuple(sorted(self._data.items())))
    
    @property
    def data(self) -> Dict[str, Any]:
        """Get data as dictionary"""
        if isinstance(self._data, tuple):
            return dict(self._data)
        return self._data or {}
    
    def get(self, key: str, default: Any = None) -> Any:
        """Get value by key"""
        return self.data.get(key, default)
    
    def set(self, key: str, value: Any) -> 'ImmutableState':
        """Create new state with updated value"""
        new_data = self.data.copy()
        new_data[key] = value
        
        return ImmutableState(
            _data=new_data,
            _version=self._version + 1,
            _created_at=time.time(),
            _parent_hash=self.hash()
        )
    
    def update(self, updates: Dict[str, Any]) -> 'ImmutableState':
        """Create new state with multiple updates"""
        new_data = self.data.copy()
        new_data.update(updates)
        
        return ImmutableState(
            _data=new_data,
            _version=self._version + 1,
            _created_at=time.time(),
            _parent_hash=self.hash()
        )
    
    def delete(self, key: str) -> 'ImmutableState':
        """Create new state with key removed"""
        new_data = self.data.copy()
        new_data.pop(key, None)
        
        return ImmutableState(
            _data=new_data,
            _version=self._version + 1,
            _created_at=time.time(),
            _parent_hash=self.hash()
        )
    
    def hash(self) -> str:
        """Get hash of current state"""
        return hashlib.md5(
            json.dumps(self.data, sort_keys=True, default=str).encode()
        ).hexdigest()
    
    def diff(self, other: 'ImmutableState') -> Dict[str, Any]:
        """Get differences between this state and another"""
        current = self.data
        other_data = other.data
        
        diff = {}
        
        # Find added/changed keys
        for key, value in current.items():
            if key not in other_data or other_data[key] != value:
                diff[key] = value
        
        # Find removed keys
        for key in other_data:
            if key not in current:
                diff[key] = None  # Indicates deletion
        
        return diff
    
    def patch(self, diff: Dict[str, Any]) -> 'ImmutableState':
        """Apply a diff to create new state"""
        new_data = self.data.copy()
        
        for key, value in diff.items():
            if value is None:
                new_data.pop(key, None)
            else:
                new_data[key] = value
        
        return ImmutableState(
            _data=new_data,
            _version=self._version + 1,
            _created_at=time.time(),
            _parent_hash=self.hash()
        )
    
    def __len__(self) -> int:
        return len(self.data)
    
    def __iter__(self):
        return iter(self.data)
    
    def __contains__(self, key):
        return key in self.data


class CopyOnWriteState:
    """
    Copy-on-write state container for efficient state management
    
    Shares memory until a write operation occurs, then creates
    a private copy for modifications.
    """
    
    def __init__(self, initial_data: Optional[Dict[str, Any]] = None):
        self._data = initial_data or {}
        self._is_shared = False
        self._version = 0
        self._created_at = time.time()
        self._write_count = 0
        self._read_count = 0
        
    def _ensure_private(self) -> None:
        """Ensure we have a private copy of the data"""
        if self._is_shared:
            self._data = copy.deepcopy(self._data)
            self._is_shared = False
            self._write_count += 1
    
    def share(self) -> 'CopyOnWriteState':
        """Create a shared reference to this state"""
        new_state = CopyOnWriteState()
        new_state._data = self._data
        new_state._is_shared = True
        new_state._version = self._version
        
        # Mark current state as shared too
        self._is_shared = True
        
        return new_state
    
    def get(self, key: str, default: Any = None) -> Any:
        """Get value by key"""
        self._read_count += 1
        return self._data.get(key, default)
    
    def set(self, key: str, value: Any) -> None:
        """Set value by key"""
        self._ensure_private()
        self._data[key] = value
        self._version += 1
    
    def update(self, updates: Dict[str, Any]) -> None:
        """Update multiple values"""
        self._ensure_private()
        self._data.update(updates)
        self._version += 1
    
    def delete(self, key: str) -> None:
        """Delete key"""
        self._ensure_private()
        self._data.pop(key, None)
        self._version += 1
    
    def copy(self) -> 'CopyOnWriteState':
        """Create a copy (uses copy-on-write)"""
        return self.share()
    
    def to_dict(self) -> Dict[str, Any]:
        """Get data as dictionary"""
        self._read_count += 1
        return self._data.copy()
    
    @property
    def is_shared(self) -> bool:
        return self._is_shared
    
    @property
    def version(self) -> int:
        return self._version
    
    @property
    def write_count(self) -> int:
        return self._write_count
    
    @property
    def read_count(self) -> int:
        return self._read_count


class LazyState:
    """
    Lazy state container that defers computation until needed
    
    Useful for expensive state computations that may not be accessed.
    """
    
    def __init__(self, compute_func: Callable[[], Any], *args, **kwargs):
        self.compute_func = compute_func
        self.args = args
        self.kwargs = kwargs
        
        self._computed = False
        self._result = None
        self._computation_time = 0.0
        self._access_count = 0
        
    def get(self) -> Any:
        """Get the computed value"""
        if not self._computed:
            start_time = time.perf_counter()
            self._result = self.compute_func(*self.args, **self.kwargs)
            self._computation_time = time.perf_counter() - start_time
            self._computed = True
        
        self._access_count += 1
        return self._result
    
    def invalidate(self) -> None:
        """Invalidate cached result"""
        self._computed = False
        self._result = None
        self._computation_time = 0.0
    
    @property
    def is_computed(self) -> bool:
        return self._computed
    
    @property
    def computation_time(self) -> float:
        return self._computation_time
    
    @property
    def access_count(self) -> int:
        return self._access_count


class StatePool:
    """
    Memory pool for state objects to reduce allocation overhead
    
    Reuses state objects to minimize garbage collection pressure.
    """
    
    def __init__(self, max_pool_size: int = 1000):
        self.max_pool_size = max_pool_size
        self._available_states: deque = deque()
        self._active_states: Set[int] = set()
        self._total_created = 0
        self._total_reused = 0
        self._lock = threading.Lock()
    
    def acquire(self, initial_data: Optional[Dict[str, Any]] = None) -> CopyOnWriteState:
        """Acquire a state object from the pool"""
        with self._lock:
            if self._available_states:
                state = self._available_states.popleft()
                # Reset the state
                state._data = initial_data or {}
                state._is_shared = False
                state._version = 0
                state._created_at = time.time()
                state._write_count = 0
                state._read_count = 0
                
                self._total_reused += 1
            else:
                state = CopyOnWriteState(initial_data)
                self._total_created += 1
            
            self._active_states.add(id(state))
            return state
    
    def release(self, state: CopyOnWriteState) -> None:
        """Release a state object back to the pool"""
        with self._lock:
            state_id = id(state)
            if state_id in self._active_states:
                self._active_states.remove(state_id)
                
                if len(self._available_states) < self.max_pool_size:
                    self._available_states.append(state)
    
    def get_stats(self) -> Dict[str, int]:
        """Get pool statistics"""
        with self._lock:
            return {
                "total_created": self._total_created,
                "total_reused": self._total_reused,
                "available_count": len(self._available_states),
                "active_count": len(self._active_states),
                "reuse_ratio": self._total_reused / max(1, self._total_created + self._total_reused)
            }


class StateDeduplicator:
    """
    State deduplication system to reduce memory usage
    
    Identifies and shares identical state objects.
    """
    
    def __init__(self, max_cache_size: int = 5000):
        self.max_cache_size = max_cache_size
        self._state_cache: OrderedDict[str, weakref.ref] = OrderedDict()
        self._hash_to_state: Dict[str, Any] = {}
        self._deduplication_count = 0
        self._lock = threading.Lock()
    
    def deduplicate(self, state: Any) -> Any:
        """Deduplicate state object if possible"""
        try:
            # Generate hash for the state
            if isinstance(state, ImmutableState):
                state_hash = state.hash()
            elif isinstance(state, CopyOnWriteState):
                state_hash = hashlib.md5(
                    json.dumps(state.to_dict(), sort_keys=True, default=str).encode()
                ).hexdigest()
            else:
                state_hash = hashlib.md5(
                    json.dumps(state, sort_keys=True, default=str).encode()
                ).hexdigest()
            
            with self._lock:
                # Check if we already have this state
                if state_hash in self._state_cache:
                    cached_ref = self._state_cache[state_hash]
                    cached_state = cached_ref()
                    
                    if cached_state is not None:
                        # Move to end (LRU)
                        self._state_cache.move_to_end(state_hash)
                        self._deduplication_count += 1
                        return cached_state
                    else:
                        # Weak reference is dead, remove it
                        del self._state_cache[state_hash]
                
                # Store new state
                self._state_cache[state_hash] = weakref.ref(state)
                self._hash_to_state[state_hash] = state
                
                # Cleanup if cache is too large
                while len(self._state_cache) > self.max_cache_size:
                    oldest_hash = next(iter(self._state_cache))
                    del self._state_cache[oldest_hash]
                    self._hash_to_state.pop(oldest_hash, None)
                
                return state
                
        except Exception:
            # If deduplication fails, return original state
            return state
    
    def get_stats(self) -> Dict[str, int]:
        """Get deduplication statistics"""
        with self._lock:
            alive_count = sum(1 for ref in self._state_cache.values() if ref() is not None)
            return {
                "cache_size": len(self._state_cache),
                "alive_references": alive_count,
                "deduplication_count": self._deduplication_count,
                "memory_saved_estimate": self._deduplication_count * 1024  # Rough estimate
            }


class OptimizedStateManager:
    """
    High-performance state manager with comprehensive optimizations
    
    Combines multiple optimization strategies for maximum performance:
    - Immutable states with structural sharing
    - Copy-on-write for mutable states
    - Lazy evaluation for expensive computations
    - Memory pooling and deduplication
    - Asynchronous operations for non-blocking updates
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        
        # Configuration
        self.enable_immutable = self.config.get("enable_immutable", True)
        self.enable_copy_on_write = self.config.get("enable_copy_on_write", True)
        self.enable_lazy = self.config.get("enable_lazy", True)
        self.enable_pooling = self.config.get("enable_pooling", True)
        self.enable_deduplication = self.config.get("enable_deduplication", True)
        self.enable_async = self.config.get("enable_async", True)
        
        # Pool configuration
        pool_config = self.config.get("pool", {})
        self.pool_size = pool_config.get("max_size", 1000)
        
        # Deduplication configuration
        dedup_config = self.config.get("deduplication", {})
        self.dedup_cache_size = dedup_config.get("max_cache_size", 5000)
        
        # Initialize components
        if self.enable_pooling:
            self._state_pool = StatePool(self.pool_size)
        else:
            self._state_pool = None
        
        if self.enable_deduplication:
            self._deduplicator = StateDeduplicator(self.dedup_cache_size)
        else:
            self._deduplicator = None
        
        # State storage
        self._states: Dict[str, Any] = {}
        self._state_versions: Dict[str, int] = {}
        self._state_locks: Dict[str, threading.Lock] = defaultdict(threading.Lock)
        
        # Async support
        if self.enable_async:
            self._executor = ThreadPoolExecutor(max_workers=4)
        else:
            self._executor = None
        
        # Metrics
        self._metrics = StateMetrics()
        self._start_time = time.time()
        
        self.logger = logging.getLogger(__name__)
    
    def create_immutable_state(self, data: Dict[str, Any]) -> ImmutableState:
        """Create an immutable state"""
        if not self.enable_immutable:
            raise RuntimeError("Immutable states not enabled")
        
        state = ImmutableState(_data=data)
        
        if self._deduplicator:
            state = self._deduplicator.deduplicate(state)
        
        return state
    
    def create_copy_on_write_state(self, data: Optional[Dict[str, Any]] = None) -> CopyOnWriteState:
        """Create a copy-on-write state"""
        if not self.enable_copy_on_write:
            raise RuntimeError("Copy-on-write states not enabled")
        
        if self._state_pool:
            state = self._state_pool.acquire(data)
        else:
            state = CopyOnWriteState(data)
        
        if self._deduplicator:
            state = self._deduplicator.deduplicate(state)
        
        return state
    
    def create_lazy_state(self, compute_func: Callable, *args, **kwargs) -> LazyState:
        """Create a lazy state"""
        if not self.enable_lazy:
            raise RuntimeError("Lazy states not enabled")
        
        return LazyState(compute_func, *args, **kwargs)
    
    def store_state(self, key: str, state: Any) -> None:
        """Store a state with given key"""
        start_time = time.perf_counter()
        
        try:
            with self._state_locks[key]:
                self._states[key] = state
                self._state_versions[key] = self._state_versions.get(key, 0) + 1
                
                # Update metrics
                self._metrics.writes_performed += 1
                write_time = time.perf_counter() - start_time
                self._update_metrics(StateOperationType.WRITE, write_time)
                
        except Exception as e:
            self.logger.error(f"Failed to store state {key}: {e}")
            self._metrics.operation_errors += 1
            raise
    
    def get_state(self, key: str, default: Any = None) -> Any:
        """Get state by key"""
        start_time = time.perf_counter()
        
        try:
            with self._state_locks[key]:
                state = self._states.get(key, default)
                
                # Update metrics
                self._metrics.reads_performed += 1
                read_time = time.perf_counter() - start_time
                self._update_metrics(StateOperationType.READ, read_time)
                
                return state
                
        except Exception as e:
            self.logger.error(f"Failed to get state {key}: {e}")
            self._metrics.operation_errors += 1
            raise
    
    def update_state(self, key: str, updates: Dict[str, Any]) -> None:
        """Update existing state"""
        start_time = time.perf_counter()
        
        try:
            with self._state_locks[key]:
                current_state = self._states.get(key)
                
                if current_state is None:
                    raise KeyError(f"State {key} not found")
                
                if isinstance(current_state, ImmutableState):
                    # Create new immutable state with updates
                    new_state = current_state.update(updates)
                    self._states[key] = new_state
                elif isinstance(current_state, CopyOnWriteState):
                    # Update copy-on-write state
                    current_state.update(updates)
                else:
                    # Handle generic state
                    if hasattr(current_state, 'update'):
                        current_state.update(updates)
                    else:
                        # Create new dict-based state
                        if isinstance(current_state, dict):
                            current_state.update(updates)
                        else:
                            self._states[key] = {**current_state, **updates}
                
                self._state_versions[key] = self._state_versions.get(key, 0) + 1
                
                # Update metrics
                self._metrics.updates_performed += 1
                update_time = time.perf_counter() - start_time
                self._update_metrics(StateOperationType.UPDATE, update_time)
                
        except Exception as e:
            self.logger.error(f"Failed to update state {key}: {e}")
            self._metrics.operation_errors += 1
            raise
    
    def delete_state(self, key: str) -> None:
        """Delete state by key"""
        start_time = time.perf_counter()
        
        try:
            with self._state_locks[key]:
                if key in self._states:
                    state = self._states.pop(key)
                    self._state_versions.pop(key, None)
                    
                    # Return to pool if applicable
                    if isinstance(state, CopyOnWriteState) and self._state_pool:
                        self._state_pool.release(state)
                    
                    # Update metrics
                    self._metrics.deletes_performed += 1
                    delete_time = time.perf_counter() - start_time
                    self._update_metrics(StateOperationType.DELETE, delete_time)
                
        except Exception as e:
            self.logger.error(f"Failed to delete state {key}: {e}")
            self._metrics.operation_errors += 1
            raise
    
    def batch_operations(self, operations: List[Tuple[str, str, Any]]) -> None:
        """
        Perform multiple state operations in batch
        
        Args:
            operations: List of (operation, key, data) tuples
                       operation can be 'set', 'update', 'delete'
        """
        start_time = time.perf_counter()
        
        try:
            # Group operations by key to minimize lock contention
            key_operations = defaultdict(list)
            for op, key, data in operations:
                key_operations[key].append((op, data))
            
            # Execute operations for each key
            for key, ops in key_operations.items():
                with self._state_locks[key]:
                    for op, data in ops:
                        if op == 'set':
                            self._states[key] = data
                        elif op == 'update':
                            self.update_state(key, data)
                        elif op == 'delete':
                            self._states.pop(key, None)
                        
                        self._state_versions[key] = self._state_versions.get(key, 0) + 1
            
            # Update metrics
            batch_time = time.perf_counter() - start_time
            self._update_metrics(StateOperationType.BATCH, batch_time)
            
        except Exception as e:
            self.logger.error(f"Batch operations failed: {e}")
            self._metrics.operation_errors += 1
            raise
    
    async def async_update_state(self, key: str, compute_func: Callable) -> None:
        """Asynchronously update state using a compute function"""
        if not self.enable_async or not self._executor:
            raise RuntimeError("Async operations not enabled")
        
        def update_operation():
            current_state = self.get_state(key)
            new_data = compute_func(current_state)
            self.update_state(key, new_data)
        
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(self._executor, update_operation)
    
    def _update_metrics(self, operation: StateOperationType, operation_time: float) -> None:
        """Update performance metrics"""
        # Update operation-specific metrics
        if operation == StateOperationType.READ:
            total_time = self._metrics.avg_read_time * (self._metrics.reads_performed - 1)
            self._metrics.avg_read_time = (total_time + operation_time) / self._metrics.reads_performed
        elif operation == StateOperationType.WRITE:
            total_time = self._metrics.avg_write_time * (self._metrics.writes_performed - 1)
            self._metrics.avg_write_time = (total_time + operation_time) / self._metrics.writes_performed
        elif operation == StateOperationType.UPDATE:
            total_time = self._metrics.avg_update_time * (self._metrics.updates_performed - 1)
            self._metrics.avg_update_time = (total_time + operation_time) / self._metrics.updates_performed
        
        # Update peak operation time
        self._metrics.peak_operation_time = max(self._metrics.peak_operation_time, operation_time)
        
        # Update memory metrics
        self._metrics.active_states = len(self._states)
        self._metrics.total_memory_bytes = sum(
            sys.getsizeof(state) for state in self._states.values()
        )
    
    def get_performance_metrics(self) -> StateMetrics:
        """Get current performance metrics"""
        # Update pool and deduplication metrics if available
        if self._state_pool:
            pool_stats = self._state_pool.get_stats()
            self._metrics.memory_saved_bytes += pool_stats["total_reused"] * 1024  # Estimate
        
        if self._deduplicator:
            dedup_stats = self._deduplicator.get_stats()
            self._metrics.state_deduplications = dedup_stats["deduplication_count"]
            self._metrics.memory_saved_bytes += dedup_stats["memory_saved_estimate"]
        
        return self._metrics
    
    def optimize_memory(self) -> Dict[str, int]:
        """Perform memory optimization operations"""
        stats = {"garbage_collected": 0, "states_cleaned": 0}
        
        # Force garbage collection
        before_gc = len(gc.get_objects())
        gc.collect()
        after_gc = len(gc.get_objects())
        stats["garbage_collected"] = before_gc - after_gc
        
        # Clean up any None references in states
        cleanup_keys = []
        for key, state in self._states.items():
            if state is None:
                cleanup_keys.append(key)
        
        for key in cleanup_keys:
            self.delete_state(key)
            stats["states_cleaned"] += 1
        
        self._metrics.garbage_collections += 1
        return stats
    
    def export_configuration(self) -> Dict[str, Any]:
        """Export current configuration"""
        return {
            "enable_immutable": self.enable_immutable,
            "enable_copy_on_write": self.enable_copy_on_write,
            "enable_lazy": self.enable_lazy,
            "enable_pooling": self.enable_pooling,
            "enable_deduplication": self.enable_deduplication,
            "enable_async": self.enable_async,
            "pool_size": self.pool_size,
            "dedup_cache_size": self.dedup_cache_size
        }
    
    def get_state_summary(self) -> Dict[str, Any]:
        """Get summary of current state storage"""
        return {
            "total_states": len(self._states),
            "state_types": {
                "immutable": sum(1 for s in self._states.values() if isinstance(s, ImmutableState)),
                "copy_on_write": sum(1 for s in self._states.values() if isinstance(s, CopyOnWriteState)),
                "lazy": sum(1 for s in self._states.values() if isinstance(s, LazyState)),
                "other": sum(1 for s in self._states.values() 
                           if not isinstance(s, (ImmutableState, CopyOnWriteState, LazyState)))
            },
            "total_versions": sum(self._state_versions.values()),
            "memory_estimate_bytes": self._metrics.total_memory_bytes
        }
    
    def shutdown(self) -> None:
        """Shutdown and cleanup resources"""
        if self._executor:
            self._executor.shutdown(wait=True)
        
        # Clear all states
        self._states.clear()
        self._state_versions.clear()
        self._state_locks.clear()


def create_optimized_state_manager(config: Optional[Dict[str, Any]] = None) -> OptimizedStateManager:
    """
    Factory function to create optimized state manager
    
    Args:
        config: Configuration dictionary
        
    Returns:
        OptimizedStateManager: Configured state manager
    """
    return OptimizedStateManager(config)


def benchmark_state_management() -> Dict[str, Any]:
    """
    Benchmark different state management configurations
    """
    print("üöÄ Starting State Management Performance Benchmark...")
    
    # Test configurations
    configs = {
        "baseline": {
            "enable_immutable": False,
            "enable_copy_on_write": False,
            "enable_lazy": False,
            "enable_pooling": False,
            "enable_deduplication": False,
            "enable_async": False
        },
        "immutable_only": {
            "enable_immutable": True,
            "enable_copy_on_write": False,
            "enable_lazy": False,
            "enable_pooling": False,
            "enable_deduplication": False,
            "enable_async": False
        },
        "copy_on_write": {
            "enable_immutable": False,
            "enable_copy_on_write": True,
            "enable_lazy": False,
            "enable_pooling": True,
            "enable_deduplication": False,
            "enable_async": False
        },
        "optimized": {
            "enable_immutable": True,
            "enable_copy_on_write": True,
            "enable_lazy": True,
            "enable_pooling": True,
            "enable_deduplication": True,
            "enable_async": False
        },
        "maximum": {
            "enable_immutable": True,
            "enable_copy_on_write": True,
            "enable_lazy": True,
            "enable_pooling": True,
            "enable_deduplication": True,
            "enable_async": True,
            "pool": {"max_size": 2000},
            "deduplication": {"max_cache_size": 10000}
        }
    }
    
    # Test data
    test_data = [
        {
            "user_id": f"user_{i}",
            "status": "active" if i % 2 == 0 else "inactive",
            "data": {"value": i, "timestamp": time.time(), "metadata": f"meta_{i}"},
            "settings": {"theme": "dark", "language": "en", "notifications": True}
        }
        for i in range(1000)
    ]
    
    results = {}
    
    for config_name, config in configs.items():
        print(f"\nüìä Testing {config_name} configuration...")
        
        manager = create_optimized_state_manager(config)
        
        # Test write operations
        start_time = time.perf_counter()
        for i, data in enumerate(test_data[:100]):
            if config.get("enable_immutable"):
                state = manager.create_immutable_state(data)
                manager.store_state(f"state_{i}", state)
            elif config.get("enable_copy_on_write"):
                state = manager.create_copy_on_write_state(data)
                manager.store_state(f"state_{i}", state)
            else:
                manager.store_state(f"state_{i}", data)
        write_time = time.perf_counter() - start_time
        
        # Test read operations
        start_time = time.perf_counter()
        for i in range(100):
            state = manager.get_state(f"state_{i}")
        read_time = time.perf_counter() - start_time
        
        # Test update operations
        start_time = time.perf_counter()
        for i in range(50):
            manager.update_state(f"state_{i}", {"updated": True, "timestamp": time.time()})
        update_time = time.perf_counter() - start_time
        
        # Get metrics
        metrics = manager.get_performance_metrics()
        summary = manager.get_state_summary()
        
        results[config_name] = {
            "write_time": write_time,
            "read_time": read_time,
            "update_time": update_time,
            "write_ops_per_sec": 100 / write_time,
            "read_ops_per_sec": 100 / read_time,
            "update_ops_per_sec": 50 / update_time,
            "memory_bytes": metrics.total_memory_bytes,
            "memory_saved_bytes": metrics.memory_saved_bytes,
            "state_deduplications": metrics.state_deduplications
        }
        
        print(f"‚úÖ {config_name}:")
        print(f"   Write: {100/write_time:.0f} ops/sec")
        print(f"   Read: {100/read_time:.0f} ops/sec")
        print(f"   Update: {50/update_time:.0f} ops/sec")
        print(f"   Memory: {metrics.total_memory_bytes/1024:.1f} KB")
        print(f"   Memory saved: {metrics.memory_saved_bytes/1024:.1f} KB")
        
        # Cleanup
        manager.shutdown()
    
    return results


if __name__ == "__main__":
    # Run performance benchmark
    try:
        benchmark_results = benchmark_state_management()
        
        print("\n" + "="*80)
        print("STATE MANAGEMENT OPTIMIZATION BENCHMARK RESULTS")
        print("="*80)
        
        for config_name, results in benchmark_results.items():
            print(f"\n[{config_name.upper()}]")
            print(f"  Write Throughput: {results['write_ops_per_sec']:.0f} ops/sec")
            print(f"  Read Throughput: {results['read_ops_per_sec']:.0f} ops/sec")
            print(f"  Update Throughput: {results['update_ops_per_sec']:.0f} ops/sec")
            print(f"  Memory Usage: {results['memory_bytes']/1024:.1f} KB")
            print(f"  Memory Saved: {results['memory_saved_bytes']/1024:.1f} KB")
            print(f"  Deduplications: {results['state_deduplications']}")
        
        print("\n‚úÖ State management optimization benchmark completed!")
        
    except Exception as e:
        print(f"‚ùå Benchmark failed: {e}")
        import traceback
        traceback.print_exc() 